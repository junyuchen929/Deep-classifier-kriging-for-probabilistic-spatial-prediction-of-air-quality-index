{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8da4d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import keras\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense, Dropout, BatchNormalization,Input\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "import keras.backend as Kr\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "from numpy import exp\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib;matplotlib.rcParams['figure.figsize'] = (10,7)\n",
    "import pylab \n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tqdm.keras import TqdmCallback\n",
    "from scipy.stats import t\n",
    "\n",
    "num_sim = 100\n",
    "\n",
    "def model_function(df_train, phi, y_train, sim_iteration):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, input_dim = phi.shape[1],kernel_initializer='he_uniform', activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=0.0012)\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
    "\n",
    "    \n",
    "    callbacks = [EarlyStopping(monitor='val_loss', patience=200),\n",
    "             ModelCheckpoint(filepath='indicator_kriging.h5',\n",
    "                             monitor='val_loss', save_best_only=True),\n",
    "             TqdmCallback(verbose=1)]\n",
    "\n",
    "    print(\"##### End of warning messages ######\")\n",
    "    print('<<<<<<<<<<<<<<<< Fitting DNN-model for %4d-th simulation >>>>>>>>>>>>>>>>>'%(sim_iteration + 1))\n",
    "    result = model.fit(phi, y_train, callbacks=callbacks,\n",
    "               validation_split = 0.1, epochs = 500, batch_size = 64, verbose = 0)\n",
    "\n",
    "    model = keras.models.load_model('indicator_kriging.h5')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1001581",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_uncertainty(models, X):\n",
    "    preds = np.array([m.predict(X).flatten() for m in models])\n",
    "    mean_pred = np.mean(preds, axis=0)\n",
    "    var_pred = np.var(preds, axis=0)\n",
    "    return mean_pred, var_pred\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def get_aleatoric_variance(s_train, s_test, residuals, k=40):\n",
    "    nbrs = NearestNeighbors(n_neighbors=k).fit(s_train)\n",
    "    _, indices = nbrs.kneighbors(s_test)\n",
    "    return np.array([np.mean(residuals[idx]) for idx in indices])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05ef2d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Deepkriging(g_val, h_val):\n",
    "    mae_list, mse_list, picp_list, al_list, time_list = [], [], [], [], []\n",
    "    n_members = 20\n",
    "\n",
    "    for sim in range(num_sim):\n",
    "        print(f\"\\n--- Simulation {sim+1}/{num_sim} ---\")\n",
    "\n",
    "        train_file = f\"synthetic_data_simulations/training_data/Tgh_nonGaussian_1600_classification_g{g_val}_h{h_val}_{sim+1}train.csv\"\n",
    "        test_file  = f\"synthetic_data_simulations/testing_data/Tgh_nonGaussian_1600_classification_g{g_val}_h{h_val}_{sim+1}test.csv\"\n",
    "        df_train = pd.read_csv(train_file)\n",
    "        df_test = pd.read_csv(test_file)\n",
    "\n",
    "        s_train = np.vstack((df_train[\"x\"], df_train[\"y\"])).T\n",
    "        s_test = np.vstack((df_test[\"x\"], df_test[\"y\"])).T\n",
    "\n",
    "        # Basis + covariates\n",
    "        num_basis = [5**2, 7**2, 11**2]\n",
    "        knots_1d = [np.linspace(0, 1, int(np.sqrt(i))) for i in num_basis]\n",
    "\n",
    "        def compute_basis(s, num_basis, knots_1d):\n",
    "            N = len(s)\n",
    "            phi = np.zeros((N, sum(num_basis)))\n",
    "            K = 0\n",
    "            for res in range(len(num_basis)):\n",
    "                theta = 1 / np.sqrt(num_basis[res]) * 2.5\n",
    "                k1, k2 = np.meshgrid(knots_1d[res], knots_1d[res])\n",
    "                knots = np.column_stack((k1.flatten(), k2.flatten()))\n",
    "                for i in range(num_basis[res]):\n",
    "                    d = np.linalg.norm(s - knots[i, :], axis=1) / theta\n",
    "                    phi[:, i + K] = np.where((d >= 0) & (d <= 1),\n",
    "                                             (1 - d) ** 6 * (35 * d**2 + 18 * d + 3) / 3, 0)\n",
    "                K += num_basis[res]\n",
    "            return phi\n",
    "\n",
    "        phi_all = compute_basis(s_train, num_basis, knots_1d)\n",
    "        phi_test = compute_basis(s_test, num_basis, knots_1d)\n",
    "        y_all = df_train[\"tgh\"].values\n",
    "        y_test = df_test[\"tgh\"].values\n",
    "\n",
    "        # === Split training data into model training and residual estimation ===\n",
    "        phi_model, phi_resid, y_model, y_resid, s_model, s_resid = train_test_split(\n",
    "            phi_all, y_all, s_train, test_size=0.5, random_state=sim\n",
    "        )\n",
    "\n",
    "        # === Train ensemble ===\n",
    "        start_time = time.time()\n",
    "        ensemble = []\n",
    "        for i in range(n_members):\n",
    "            phi_sub, _, y_sub, _ = train_test_split(\n",
    "                phi_model, y_model, test_size=0.1, random_state=sim * 100 + i)\n",
    "\n",
    "            try:\n",
    "                model = model_function(df_train, phi_sub, y_sub, sim * 100 + i)\n",
    "                ensemble.append(model)\n",
    "            except Exception as e:\n",
    "                print(f\"[Warning] Model {i} in Sim {sim+1} failed: {str(e)}\")\n",
    "                continue\n",
    "        train_time = time.time() - start_time\n",
    "        time_list.append(train_time)\n",
    "\n",
    "        # === Predict on test set ===\n",
    "        mean_pred, var_pred = predict_with_uncertainty(ensemble, phi_test)\n",
    "\n",
    "        # === Predict on residual estimation set ===\n",
    "        train_preds = np.array([m.predict(phi_resid).flatten() for m in ensemble])\n",
    "        train_mean_pred = np.mean(train_preds, axis=0)\n",
    "        train_var_pred = np.var(train_preds, axis=0)\n",
    "        residuals = (y_resid - train_mean_pred) ** 2 - train_var_pred\n",
    "        residuals[residuals < 0] = 0  # avoid negative variance\n",
    "\n",
    "        # === Estimate aleatoric variance from neighbors of s_resid ===\n",
    "        r_pred = get_aleatoric_variance(s_resid, s_test, residuals, k=40)\n",
    "\n",
    "        # === Final PI ===\n",
    "        std_total = np.sqrt(var_pred + r_pred)\n",
    "        lower = mean_pred - 1.96 * std_total\n",
    "        upper = mean_pred + 1.96 * std_total\n",
    "\n",
    "        # === Metrics ===\n",
    "        mae = np.mean(np.abs(y_test - mean_pred))\n",
    "        mse = np.mean((y_test - mean_pred) ** 2)\n",
    "        picp = np.mean((y_test >= lower) & (y_test <= upper))\n",
    "        al = np.mean(upper - lower)\n",
    "\n",
    "        print(f\"[Sim {sim+1}] g={g_val}, h={h_val} | MAE={mae:.3f}, MSE={mse:.3f}, PICP={picp:.3f}, AL={al:.3f}, Time={train_time:.2f}s\")\n",
    "        mae_list.append(mae)\n",
    "        mse_list.append(mse)\n",
    "        picp_list.append(picp)\n",
    "        al_list.append(al)\n",
    "\n",
    "    # === Save summary ===\n",
    "    df = pd.DataFrame({\n",
    "        \"MAE\": mae_list,\n",
    "        \"MSE\": mse_list,\n",
    "        \"PICP\": picp_list,\n",
    "        \"AL\": al_list,\n",
    "        \"Train_Time\": time_list\n",
    "    })\n",
    "    df.to_csv(\"results_with_interval.csv\", index=False)\n",
    "\n",
    "    print(f\"\\nAverage Training Time over {num_sim} simulations: {np.nanmean(time_list):.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fdfdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Deepkriging(0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d327817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_Time mean: 141.513\n",
      "MAE mean: 0.183\n",
      "MAE SE: 0.001\n",
      "PICP mean: 0.950\n",
      "PICP SE: 0.002\n",
      "AL mean: 0.931\n",
      "AL SE: 0.003\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"results_with_interval.csv\")\n",
    "n = len(df)\n",
    "\n",
    "train_time_mean = np.mean(df['Train_Time'])\n",
    "\n",
    "picp_mean = np.mean(df['PICP'])\n",
    "picp_se = np.std(df['PICP'], ddof=1) / np.sqrt(n)\n",
    "\n",
    "al_mean = np.mean(df['AL'])\n",
    "al_se = np.std(df['AL'], ddof=1) / np.sqrt(n)\n",
    "\n",
    "print(\"Train_Time mean:\", \"{:.3f}\".format(train_time_mean))\n",
    "print(\"PICP mean:\", \"{:.3f}\".format(picp_mean))\n",
    "print(\"PICP SE:\", \"{:.3f}\".format(picp_se))\n",
    "print(\"AL mean:\", \"{:.3f}\".format(al_mean))\n",
    "print(\"AL SE:\", \"{:.3f}\".format(al_se))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d85ffc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Deepkriging_mae(g_val, h_val):\n",
    "    mae_list = []\n",
    "    mse_list = []\n",
    "    time_list = []\n",
    "    \n",
    "    for sim in range(num_sim):\n",
    "        train_file = f\"synthetic_data_simulations/training_data/Tgh_nonGaussian_1600_classification_g{g_val}_h{h_val}_{sim+1}train.csv\"\n",
    "        test_file  = f\"synthetic_data_simulations/testing_data/Tgh_nonGaussian_1600_classification_g{g_val}_h{h_val}_{sim+1}test.csv\"\n",
    "        df_train = pd.read_csv(train_file)\n",
    "        df_test = pd.read_csv(test_file)\n",
    "        \n",
    "        s_train = np.vstack((df_train[\"x\"], df_train[\"y\"])).T\n",
    "        s_test = np.vstack((df_test[\"x\"], df_test[\"y\"])).T\n",
    "\n",
    "        num_basis = [5**2, 7**2, 11**2]\n",
    "        knots_1d = [np.linspace(0, 1, int(np.sqrt(i))) for i in num_basis]\n",
    "\n",
    "        def compute_basis(s, num_basis, knots_1d):\n",
    "            N = len(s)\n",
    "            phi = np.zeros((N, sum(num_basis)))\n",
    "            K = 0\n",
    "            for res in range(len(num_basis)):\n",
    "                theta = 1 / np.sqrt(num_basis[res]) * 2.5\n",
    "                k1, k2 = np.meshgrid(knots_1d[res], knots_1d[res])\n",
    "                knots = np.column_stack((k1.flatten(), k2.flatten()))\n",
    "                for i in range(num_basis[res]):\n",
    "                    d = np.linalg.norm(s - knots[i, :], axis=1) / theta\n",
    "                    phi[:, i + K] = np.where(\n",
    "                        (d >= 0) & (d <= 1),\n",
    "                        (1 - d) ** 6 * (35 * d**2 + 18 * d + 3) / 3,\n",
    "                        0\n",
    "                    )\n",
    "                K += num_basis[res]\n",
    "            return phi\n",
    "\n",
    "        phi_train = compute_basis(s_train, num_basis, knots_1d)\n",
    "        phi_test = compute_basis(s_test, num_basis, knots_1d)\n",
    "\n",
    "        y_train = df_train[\"tgh\"].values\n",
    "        y_test = df_test[\"tgh\"].values\n",
    "        \n",
    "        start_time = time.time()\n",
    "        model = model_function(df_train, phi_train, y_train, sim)\n",
    "        train_time = time.time() - start_time\n",
    "\n",
    "        y_pred = model.predict(phi_test).flatten()\n",
    "\n",
    "        mae = np.mean(np.abs(y_test - y_pred))\n",
    "        mse = np.mean((y_test - y_pred) ** 2)\n",
    "        \n",
    "        print(f\"[Sim {sim+1}] g={g_val}, h={h_val} | MAE: {mae:.4f}, MSE: {mse:.4f}, Time: {train_time:.2f} sec\")\n",
    "        \n",
    "        mae_list.append(mae)\n",
    "        mse_list.append(mse)\n",
    "        time_list.append(train_time)\n",
    "\n",
    "    # Final output\n",
    "    avg_time = np.mean(time_list)\n",
    "    print(f\"Average training time: {avg_time:.2f} sec\")\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"MAE\": mae_list,\n",
    "        \"MSE\": mse_list,\n",
    "        \"Time\": time_list\n",
    "    })\n",
    "\n",
    "    # Add average as final row\n",
    "    df.loc[\"Average\"] = [np.mean(mae_list), np.mean(mse_list), avg_time]\n",
    "    df.to_csv(\"results.csv\", index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcafc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "Deepkriging_mae(0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a8b43fc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.644980655363968"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"results.csv\")\n",
    "np.mean(df2['MAE'])\n",
    "np.std(df2['MAE'],ddof=1)/10\n",
    "np.mean(df2['Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b709641",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
