{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8779ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbcd29f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9n/7bxqt9q92tl6lchpfwnymvjh0000gn/T/ipykernel_76533/1275416242.py:2: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"Gold.csv\",sep = \",\")\n"
     ]
    }
   ],
   "source": [
    "# Gold\n",
    "df = pd.read_csv(\"Gold.csv\",sep = \",\")\n",
    "df['Date Local'] = pd.to_datetime(df['Date Local'], errors='coerce')\n",
    "df_jan = df[(df['Date Local'] >= '2019-01-01') & (df['Date Local'] <= '2019-01-31')]\n",
    "df_jan = df_jan[['Latitude', 'Longitude', 'AQI']]\n",
    "# df_jan = df_jan[['Latitude', 'Longitude', 'Arithmetic Mean']]\n",
    "df_avg = df_jan.groupby(['Latitude', 'Longitude'], as_index=False).mean()\n",
    "df_avg.to_csv(\"Gold_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31ea6814",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9n/7bxqt9q92tl6lchpfwnymvjh0000gn/T/ipykernel_5704/3912202928.py:2: DtypeWarning: Columns (2,3,4,5,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df3 = pd.read_csv(\"CMAQ.csv\", skiprows=2)\n"
     ]
    }
   ],
   "source": [
    "#CMAQ\n",
    "df3 = pd.read_csv(\"CMAQ.csv\", skiprows=2)\n",
    "df3 = df3.iloc[1:]\n",
    "df4 = df3[['latitude', 'longitude', 'PM25_AVG']].copy()\n",
    "df4['latitude'] = pd.to_numeric(df4['latitude'], errors='coerce').round(6)\n",
    "df4['longitude'] = pd.to_numeric(df4['longitude'], errors='coerce').round(6)\n",
    "df4['PM25_AVG'] = pd.to_numeric(df4['PM25_AVG'], errors='coerce')\n",
    "df_avg2 = df4.groupby(['latitude', 'longitude'], as_index=False).mean()\n",
    "df_avg2.to_csv(\"CMAQ_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9818dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gold_clean_land: lat=(25.472, 48.760), lon=(-124.179, -68.016), count=918\n",
      "CMAQ_clean_land: lat=(25.166, 49.318), lon=(-124.639, -67.110), count=53757\n",
      "\n",
      "--- Region: CA ---\n",
      "FRM_CA_subset: lat=(32.631, 41.727), lon=(-124.179, -115.483), count=112\n",
      "CMAQ_CA_subset: lat=(32.554, 42.009), lon=(-124.320, -114.181), count=2787\n",
      "\n",
      "--- Region: NE ---\n",
      "FRM_NE_subset: lat=(39.422, 44.393), lon=(-80.485, -70.971), count=96\n",
      "CMAQ_NE_subset: lat=(38.959, 44.999), lon=(-80.520, -69.975), count=1953\n",
      "\n",
      "--- Region: SE ---\n",
      "FRM_SE_subset: lat=(25.472, 34.979), lon=(-88.088, -79.767), count=78\n",
      "CMAQ_SE_subset: lat=(25.166, 35.178), lon=(-88.458, -78.691), count=3573\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def print_range(name, df):\n",
    "    print(f\"{name}: lat=({df['lat'].min():.3f}, {df['lat'].max():.3f}), \"\n",
    "          f\"lon=({df['lon'].min():.3f}, {df['lon'].max():.3f}), \"\n",
    "          f\"count={len(df)}\")\n",
    "\n",
    "# =============================\n",
    "# Full-land datasets\n",
    "# =============================\n",
    "df_g = pd.read_csv(\"Gold_clean_land.csv\")\n",
    "df_c = pd.read_csv(\"CMAQ_clean_land.csv\")\n",
    "\n",
    "print_range(\"Gold_clean_land\", df_g)\n",
    "print_range(\"CMAQ_clean_land\", df_c)\n",
    "\n",
    "# =============================\n",
    "# Subsets: CA / NE / SE\n",
    "# =============================\n",
    "regions = [\"CA\", \"NE\", \"SE\"]\n",
    "\n",
    "for r in regions:\n",
    "    df_frm = pd.read_csv(f\"FRM_{r}_subset.csv\")\n",
    "    df_cmaq = pd.read_csv(f\"CMAQ_{r}_subset.csv\")\n",
    "    \n",
    "    print(\"\\n--- Region:\", r, \"---\")\n",
    "    print_range(f\"FRM_{r}_subset\", df_frm)\n",
    "    print_range(f\"CMAQ_{r}_subset\", df_cmaq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64025d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get CVS1: \n",
    "# This is U2 Part (about 1000 data) si, Z1 and closest uj and Z2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Load and rename\n",
    "df_gold = pd.read_csv(\"Gold_clean_land.csv\")\n",
    "df_cmaq = pd.read_csv(\"CMAQ_clean_land.csv\")\n",
    "\n",
    "df_gold = df_gold.rename(columns={'lat': 'si_lat', 'lon': 'si_lon', 'AQI': 'Z1'})\n",
    "#df_gold = df_gold.rename(columns={'Latitude': 'si_lat', 'Longitude': 'si_lon', 'Arithmetic Mean': 'Z1'})\n",
    "\n",
    "df_cmaq = df_cmaq.rename(columns={'lat': 'uj_lat', 'lon': 'uj_lon', 'PM25': 'Z2'})\n",
    "\n",
    "# Round coordinates to avoid float precision issues\n",
    "df_gold['si_lat'] = df_gold['si_lat'].round(5)\n",
    "df_gold['si_lon'] = df_gold['si_lon'].round(5)\n",
    "df_cmaq['uj_lat'] = df_cmaq['uj_lat'].round(5)\n",
    "df_cmaq['uj_lon'] = df_cmaq['uj_lon'].round(5)\n",
    "\n",
    "# Prepare for NearestNeighbor\n",
    "X_gold = df_gold[['si_lat', 'si_lon']].to_numpy()\n",
    "X_cmaq = df_cmaq[['uj_lat', 'uj_lon']].to_numpy()\n",
    "\n",
    "# Find nearest uj for each si\n",
    "nbrs = NearestNeighbors(n_neighbors=1, algorithm='ball_tree')\n",
    "nbrs.fit(X_cmaq)\n",
    "distances, indices = nbrs.kneighbors(X_gold)\n",
    "\n",
    "# Get nearest Z2\n",
    "nearest_cmaq = df_cmaq.iloc[indices.flatten()].reset_index(drop=True)\n",
    "df_gold_reset = df_gold.reset_index(drop=True)\n",
    "\n",
    "# Merge and round again just in case\n",
    "df_matched = pd.concat([df_gold_reset, nearest_cmaq], axis=1)\n",
    "df_matched[['uj_lat', 'uj_lon']] = df_matched[['uj_lat', 'uj_lon']].round(5)\n",
    "\n",
    "# Final output\n",
    "df_csv1 = df_matched[['si_lat', 'si_lon', 'uj_lat', 'uj_lon', 'Z1', 'Z2']]\n",
    "df_csv1.to_csv(\"CSV1_land.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6031b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing region: CA...\n",
      "Saved: CSV1_CA.csv  (N=108)\n",
      "\n",
      "Processing region: NE...\n",
      "Saved: CSV1_NE.csv  (N=95)\n",
      "\n",
      "Processing region: SE...\n",
      "Saved: CSV1_SE.csv  (N=77)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "regions = [\"CA\", \"NE\", \"SE\"]\n",
    "\n",
    "for reg in regions:\n",
    "    print(f\"Processing region: {reg}...\")\n",
    "\n",
    "    # Load subset files\n",
    "    df_gold = pd.read_csv(f\"FRM_{reg}_subset.csv\")\n",
    "    df_cmaq = pd.read_csv(f\"CMAQ_{reg}_subset.csv\")\n",
    "\n",
    "    # Rename columns\n",
    "    df_gold = df_gold.rename(columns={'lat': 'si_lat', 'lon': 'si_lon', 'AQI': 'Z1'})\n",
    "    df_cmaq = df_cmaq.rename(columns={'lat': 'uj_lat', 'lon': 'uj_lon', 'PM25': 'Z2'})\n",
    "\n",
    "    # Round coords\n",
    "    df_gold[['si_lat', 'si_lon']] = df_gold[['si_lat', 'si_lon']].round(5)\n",
    "    df_cmaq[['uj_lat', 'uj_lon']] = df_cmaq[['uj_lat', 'uj_lon']].round(5)\n",
    "\n",
    "    # Prepare nearest neighbor search\n",
    "    X_gold = df_gold[['si_lat', 'si_lon']].to_numpy()\n",
    "    X_cmaq = df_cmaq[['uj_lat', 'uj_lon']].to_numpy()\n",
    "\n",
    "    nbrs = NearestNeighbors(n_neighbors=1, algorithm='ball_tree')\n",
    "    nbrs.fit(X_cmaq)\n",
    "    distances, indices = nbrs.kneighbors(X_gold)\n",
    "\n",
    "    # Match nearest CMAQ point\n",
    "    nearest_cmaq = df_cmaq.iloc[indices.flatten()].reset_index(drop=True)\n",
    "    df_gold_reset = df_gold.reset_index(drop=True)\n",
    "\n",
    "    # Merge\n",
    "    df_matched = pd.concat([df_gold_reset, nearest_cmaq], axis=1)\n",
    "    df_matched[['uj_lat', 'uj_lon']] = df_matched[['uj_lat', 'uj_lon']].round(5)\n",
    "\n",
    "    # Final CSV1 output for region\n",
    "    df_csv1 = df_matched[['si_lat', 'si_lon', 'uj_lat', 'uj_lon', 'Z1', 'Z2']]\n",
    "    df_csv1.to_csv(f\"CSV1_{reg}.csv\", index=False)\n",
    "\n",
    "    print(f\"Saved: CSV1_{reg}.csv  (N={len(df_csv1)})\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ec0f486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# U1/U2: CSV2\n",
    "df_cmaq = pd.read_csv(\"CMAQ_clean.csv\")\n",
    "df_cmaq = df_cmaq.rename(columns={'latitude': 'uj_lat', 'longitude': 'uj_lon', 'PM25_AVG': 'Z2'})\n",
    "df_csv1 = pd.read_csv(\"CSV1.csv\")\n",
    "\n",
    "df_cmaq['uj_lat'] = df_cmaq['uj_lat'].round(5)\n",
    "df_cmaq['uj_lon'] = df_cmaq['uj_lon'].round(5)\n",
    "df_csv1['uj_lat'] = df_csv1['uj_lat'].round(5)\n",
    "df_csv1['uj_lon'] = df_csv1['uj_lon'].round(5)\n",
    "\n",
    "df_cmaq_unique = df_cmaq.drop_duplicates(subset=['uj_lat', 'uj_lon'])\n",
    "df_csv1_unique = df_csv1[['uj_lat', 'uj_lon']].drop_duplicates()\n",
    "\n",
    "df_unmatched = df_cmaq_unique.merge(\n",
    "    df_csv1_unique,\n",
    "    on=['uj_lat', 'uj_lon'],\n",
    "    how='left',\n",
    "    indicator=True\n",
    ")\n",
    "\n",
    "df_unmatched = df_unmatched[df_unmatched['_merge'] == 'left_only'].drop(columns=['_merge'])\n",
    "\n",
    "df_unmatched.to_csv(\"CSV2.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25439dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing region: CA...\n",
      "Saved: CSV2_CA.csv (N=2686)\n",
      "\n",
      "Processing region: NE...\n",
      "Saved: CSV2_NE.csv (N=1873)\n",
      "\n",
      "Processing region: SE...\n",
      "Saved: CSV2_SE.csv (N=3499)\n",
      "\n",
      "ðŸŽ¯ Successfully generated CSV2_CA/NE/SE.csv for all regions!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "regions = [\"CA\", \"NE\", \"SE\"]\n",
    "\n",
    "for reg in regions:\n",
    "    print(f\"Processing region: {reg}...\")\n",
    "\n",
    "    # Load subset files\n",
    "    df_gold = pd.read_csv(f\"FRM_{reg}_subset.csv\")\n",
    "    df_cmaq = pd.read_csv(f\"CMAQ_{reg}_subset.csv\")\n",
    "\n",
    "    # Rename columns\n",
    "    df_gold = df_gold.rename(columns={'lat': 'si_lat', 'lon': 'si_lon'})\n",
    "    df_cmaq = df_cmaq.rename(columns={'lat': 'uj_lat', 'lon': 'uj_lon', 'PM25': 'Z2'})\n",
    "\n",
    "    # Round coordinates\n",
    "    df_gold[['si_lat', 'si_lon']] = df_gold[['si_lat', 'si_lon']].round(5)\n",
    "    df_cmaq[['uj_lat', 'uj_lon']] = df_cmaq[['uj_lat', 'uj_lon']].round(5)\n",
    "\n",
    "    # Remove duplicates in CMAQ grid\n",
    "    df_cmaq_unique = df_cmaq.drop_duplicates(subset=['uj_lat', 'uj_lon'])\n",
    "\n",
    "    # Only keep coordinates columns for matching\n",
    "    df_csv1 = pd.read_csv(f\"CSV1_{reg}.csv\")\n",
    "    df_csv1_coords = df_csv1[['uj_lat', 'uj_lon']].drop_duplicates()\n",
    "\n",
    "    # Find CMAQ points **NOT** used in CSV1 (i.e., not matched with FRM)\n",
    "    df_unmatched = df_cmaq_unique.merge(\n",
    "        df_csv1_coords,\n",
    "        on=['uj_lat', 'uj_lon'],\n",
    "        how='left',\n",
    "        indicator=True\n",
    "    )\n",
    "    df_unmatched = df_unmatched[df_unmatched['_merge'] == 'left_only']\n",
    "    df_unmatched = df_unmatched.drop(columns=['_merge'])\n",
    "\n",
    "    # Only keep required columns Z2 + coords\n",
    "    df_csv2 = df_unmatched[['uj_lat', 'uj_lon', 'Z2']]\n",
    "    df_csv2.to_csv(f\"CSV2_{reg}.csv\", index=False)\n",
    "\n",
    "    print(f\"Saved: CSV2_{reg}.csv (N={len(df_csv2)})\\n\")\n",
    "\n",
    "print(\"ðŸŽ¯ Successfully generated CSV2_CA/NE/SE.csv for all regions!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b018399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_csv1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a40f956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "df_csv1_train, df_csv1_test = train_test_split(df_csv1, test_size=0.2, random_state=42)\n",
    "df_csv1_train.to_csv(\"CSV1_train.csv\", index=False)\n",
    "df_csv1_test.to_csv(\"CSV1_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "642bb4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting CSV1 for region: CA...\n",
      "Saved: CSV1_CA_train.csv (N=86)\n",
      "Saved: CSV1_CA_test.csv (N=22)\n",
      "\n",
      "Splitting CSV1 for region: NE...\n",
      "Saved: CSV1_NE_train.csv (N=76)\n",
      "Saved: CSV1_NE_test.csv (N=19)\n",
      "\n",
      "Splitting CSV1 for region: SE...\n",
      "Saved: CSV1_SE_train.csv (N=61)\n",
      "Saved: CSV1_SE_test.csv (N=16)\n",
      "\n",
      "ðŸŽ¯ Region-wise train/test split completed successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "regions = [\"CA\", \"NE\", \"SE\"]\n",
    "\n",
    "for reg in regions:\n",
    "    print(f\"Splitting CSV1 for region: {reg}...\")\n",
    "\n",
    "    df_csv1 = pd.read_csv(f\"CSV1_{reg}.csv\")\n",
    "\n",
    "    # 80% training, 20% testing\n",
    "    df_train, df_test = train_test_split(\n",
    "        df_csv1, \n",
    "        test_size=0.2, \n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    df_train.to_csv(f\"CSV1_{reg}_train.csv\", index=False)\n",
    "    df_test.to_csv(f\"CSV1_{reg}_test.csv\", index=False)\n",
    "\n",
    "    print(f\"Saved: CSV1_{reg}_train.csv (N={len(df_train)})\")\n",
    "    print(f\"Saved: CSV1_{reg}_test.csv (N={len(df_test)})\\n\")\n",
    "\n",
    "print(\"ðŸŽ¯ Region-wise train/test split completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bac5a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv1_test = pd.read_csv(\"CSV1_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f801053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_csv1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "740ca7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_proj = pd.read_csv(\"projection_matrix_total.csv\")\n",
    "df_csv1_test = pd.read_csv(\"CSV1_test.csv\")\n",
    "\n",
    "\n",
    "df_proj_csv1_like = df_proj[(df_proj[\"Z1\"] - df_proj[\"proj_Z1\"]).abs() > 1e-8]\n",
    "\n",
    "\n",
    "keys = ['uj_lat','uj_lon','Z1','Z2']\n",
    "def rounded_view(df, cols=keys, nd=6):\n",
    "    v = df[cols].astype(float).copy()\n",
    "    for c in cols:\n",
    "        v[c] = v[c].round(nd)\n",
    "    return v\n",
    "\n",
    "rv_proj_csv1_like = rounded_view(df_proj_csv1_like)         \n",
    "rv_csv1_test      = rounded_view(df_csv1_test)               \n",
    "\n",
    "# test = CSV1-like âˆ© CSV1_test\n",
    "df_proj_test_idx = rv_proj_csv1_like.merge(\n",
    "    rv_csv1_test.drop_duplicates(), on=keys, how='inner'\n",
    ").index\n",
    "\n",
    "\n",
    "df_proj_test = df_proj_csv1_like.iloc[df_proj_test_idx].copy()\n",
    "\n",
    "\n",
    "rv_proj_all = rounded_view(df_proj)                          \n",
    "rv_test_keys = rounded_view(df_proj_test).drop_duplicates()  \n",
    "\n",
    "anti = rv_proj_all.merge(rv_test_keys, on=keys, how='left', indicator=True)\n",
    "keep_mask = anti['_merge'].eq('left_only').to_numpy()\n",
    "\n",
    "\n",
    "df_proj_train = df_proj.loc[keep_mask].copy()\n",
    "\n",
    "\n",
    "assert len(df_proj) == len(df_proj_train) + len(df_proj_test), \\\n",
    "    f\"mismatch: total={len(df_proj)}, train={len(df_proj_train)}, test={len(df_proj_test)}\"\n",
    "\n",
    "\n",
    "df_proj_train.to_csv(\"projection_matrix_train.csv\", index=False)\n",
    "df_proj_test.to_csv(\"projection_matrix_test.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30e18e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "Processing region: CA\n",
      "==============================\n",
      "âœ” Saved projection_matrix_CA_train.csv (N=2773)\n",
      "âœ” Saved projection_matrix_CA_test.csv  (N=22)\n",
      "\n",
      "==============================\n",
      "Processing region: NE\n",
      "==============================\n",
      "âœ” Saved projection_matrix_NE_train.csv (N=1950)\n",
      "âœ” Saved projection_matrix_NE_test.csv  (N=19)\n",
      "\n",
      "==============================\n",
      "Processing region: SE\n",
      "==============================\n",
      "âœ” Saved projection_matrix_SE_train.csv (N=3560)\n",
      "âœ” Saved projection_matrix_SE_test.csv  (N=16)\n",
      "\n",
      "ðŸŽ¯ Projection matrix train/test split done for all regions!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "regions = [\"CA\", \"NE\", \"SE\"]\n",
    "\n",
    "for reg in regions:\n",
    "    print(f\"\\n==============================\")\n",
    "    print(f\"Processing region: {reg}\")\n",
    "    print(\"==============================\")\n",
    "\n",
    "    # Load projection matrix & test CSV1 for this region\n",
    "    df_proj = pd.read_csv(f\"projection_matrix_{reg}.csv\")\n",
    "    df_csv1_test = pd.read_csv(f\"CSV1_{reg}_test.csv\")\n",
    "\n",
    "    keys = ['uj_lat','uj_lon','Z1','Z2']\n",
    "\n",
    "    def rounded_view(df, cols=keys, nd=6):\n",
    "        v = df[cols].astype(float).copy()\n",
    "        for c in cols:\n",
    "            v[c] = v[c].round(nd)\n",
    "        return v\n",
    "\n",
    "    # Round views for matching\n",
    "    rv_proj = rounded_view(df_proj)\n",
    "    rv_csv1_test = rounded_view(df_csv1_test)\n",
    "\n",
    "    df_proj_test_idx = rv_proj.merge(\n",
    "        rv_csv1_test.drop_duplicates(),\n",
    "        on=keys,\n",
    "        how='inner'\n",
    "    ).index\n",
    "\n",
    "    df_proj_test = df_proj.iloc[df_proj_test_idx].copy()\n",
    "\n",
    "    rv_test_keys = rounded_view(df_proj_test).drop_duplicates()\n",
    "    anti = rv_proj.merge(rv_test_keys, on=keys, how='left', indicator=True)\n",
    "    keep_mask = anti['_merge'].eq('left_only').to_numpy()\n",
    "    df_proj_train = df_proj[keep_mask].copy()\n",
    "\n",
    "    # Check consistency\n",
    "    assert len(df_proj) == len(df_proj_train) + len(df_proj_test), \\\n",
    "        f\"[{reg}] mismatch: total={len(df_proj)}, train={len(df_proj_train)}, test={len(df_proj_test)}\"\n",
    "\n",
    "    # Save output\n",
    "    df_proj_train.to_csv(f\"projection_matrix_{reg}_train.csv\", index=False)\n",
    "    df_proj_test.to_csv(f\"projection_matrix_{reg}_test.csv\", index=False)\n",
    "\n",
    "    print(f\"âœ” Saved projection_matrix_{reg}_train.csv (N={len(df_proj_train)})\")\n",
    "    print(f\"âœ” Saved projection_matrix_{reg}_test.csv  (N={len(df_proj_test)})\")\n",
    "\n",
    "print(\"\\nðŸŽ¯ Projection matrix train/test split done for all regions!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7488b0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "Processing region: CA\n",
      "==============================\n",
      "âœ” Saved: projection_matrix_CA_train.csv (N=2773)\n",
      "âœ” Saved: projection_matrix_CA_test.csv  (N=22)\n",
      "âœ” Saved: projection_matrix_CA_train_FRM.csv (N=86)  <-- YOU WANT THIS\n",
      "\n",
      "==============================\n",
      "Processing region: NE\n",
      "==============================\n",
      "âœ” Saved: projection_matrix_NE_train.csv (N=1950)\n",
      "âœ” Saved: projection_matrix_NE_test.csv  (N=19)\n",
      "âœ” Saved: projection_matrix_NE_train_FRM.csv (N=76)  <-- YOU WANT THIS\n",
      "\n",
      "==============================\n",
      "Processing region: SE\n",
      "==============================\n",
      "âœ” Saved: projection_matrix_SE_train.csv (N=3560)\n",
      "âœ” Saved: projection_matrix_SE_test.csv  (N=16)\n",
      "âœ” Saved: projection_matrix_SE_train_FRM.csv (N=61)  <-- YOU WANT THIS\n",
      "\n",
      "âœ¨ Part-1 FRM training subsets also saved! ðŸŽ¯\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "regions = [\"CA\", \"NE\", \"SE\"]\n",
    "\n",
    "for reg in regions:\n",
    "    print(f\"\\n==============================\")\n",
    "    print(f\"Processing region: {reg}\")\n",
    "    print(\"==============================\")\n",
    "\n",
    "    df_proj = pd.read_csv(f\"projection_matrix_{reg}.csv\")\n",
    "    df_csv1_test = pd.read_csv(f\"CSV1_{reg}_test.csv\")\n",
    "    df_csv1_train = pd.read_csv(f\"CSV1_{reg}_train.csv\")  # NEW ðŸ”¥\n",
    "\n",
    "    keys = ['uj_lat','uj_lon','Z1','Z2']\n",
    "\n",
    "    def rounded_view(df, cols=keys, nd=6):\n",
    "        v = df[cols].astype(float).copy()\n",
    "        for c in cols:\n",
    "            v[c] = v[c].round(nd)\n",
    "        return v\n",
    "\n",
    "    rv_proj = rounded_view(df_proj)\n",
    "    rv_csv1_test = rounded_view(df_csv1_test)\n",
    "    rv_csv1_train = rounded_view(df_csv1_train)\n",
    "\n",
    "    # ====== TEST subset ======\n",
    "    df_proj_test_idx = rv_proj.merge(\n",
    "        rv_csv1_test.drop_duplicates(),\n",
    "        on=keys, how='inner'\n",
    "    ).index\n",
    "    df_proj_test = df_proj.iloc[df_proj_test_idx].copy()\n",
    "\n",
    "    # ====== FRM TRAIN subset (Part 1 you requested) ======\n",
    "    df_proj_train_FRM_idx = rv_proj.merge(\n",
    "        rv_csv1_train.drop_duplicates(),\n",
    "        on=keys, how='inner'\n",
    "    ).index\n",
    "    df_proj_train_FRM = df_proj.iloc[df_proj_train_FRM_idx].copy()\n",
    "\n",
    "    # ====== FULL TRAIN = ALL - Test ======\n",
    "    rv_test_keys = rounded_view(df_proj_test).drop_duplicates()\n",
    "    anti = rv_proj.merge(rv_test_keys, on=keys, how='left', indicator=True)\n",
    "    keep_mask = anti['_merge'].eq('left_only').to_numpy()\n",
    "    df_proj_train = df_proj[keep_mask].copy()\n",
    "\n",
    "    assert len(df_proj) == len(df_proj_train) + len(df_proj_test), \\\n",
    "        f\"[{reg}] mismatch total={len(df_proj)}, train={len(df_proj_train)}, test={len(df_proj_test)}\"\n",
    "\n",
    "    # ====== SAVE ======\n",
    "#     df_proj_train.to_csv(f\"projection_matrix_{reg}_train.csv\", index=False)\n",
    "#     df_proj_test.to_csv(f\"projection_matrix_{reg}_test.csv\", index=False)\n",
    "    df_proj_train_FRM.to_csv(f\"projection_matrix_{reg}_train_FRM.csv\", index=False)  # NEW ðŸ”¥\n",
    "\n",
    "    print(f\"âœ” Saved: projection_matrix_{reg}_train.csv (N={len(df_proj_train)})\")\n",
    "    print(f\"âœ” Saved: projection_matrix_{reg}_test.csv  (N={len(df_proj_test)})\")\n",
    "    print(f\"âœ” Saved: projection_matrix_{reg}_train_FRM.csv (N={len(df_proj_train_FRM)})  <-- YOU WANT THIS\")\n",
    "\n",
    "print(\"\\nâœ¨ Part-1 FRM training subsets also saved! ðŸŽ¯\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13cf711b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10873"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_proj_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b0d70ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_proj_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841397d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
